{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3N3SNc1NYLsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STATISTICS ADVANCE PART 2"
      ],
      "metadata": {
        "id": "y3SQ03zqYNyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics?\n",
        "- Hypothesis testing is a fundamental method in statistics used to make decisions or inferences about population parameters based on sample data.\n",
        "\n",
        "-  Definition\n",
        "Hypothesis testing is a procedure for testing a claim or hypothesis about a parameter in a population, using data measured in a sample.\n",
        "2. > What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "- The null hypothesis (H‚ÇÄ) is a statement that there is no effect, no difference, or no relationship between variables. It represents the status quo or a baseline assumption that you test against.\n",
        "\n",
        "- Purpose: To provide a benchmark for testing whether an observed effect is statistically significant.\n",
        "\n",
        "- Assumed to be true until evidence suggests otherwise.\n",
        "- The alternative hypothesis is a statement that contradicts the null hypothesis. It represents what you want to prove ‚Äî that there is an effect, difference, or relationship.\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "- The significance level, denoted by Œ± (alpha), is the threshold probability you set before conducting a hypothesis test to decide how strong the evidence must be to reject the null hypothesis (H‚ÇÄ).\n",
        "-  Why Is It Important?\n",
        "- 1 . Controls Risk of False Positives\n",
        "\n",
        "- It sets your tolerance for error when detecting an effect that may not actually exist.\n",
        "\n",
        "- 2 . Determines Decision Threshold\n",
        "\n",
        "- You reject H‚ÇÄ only if the p-value ‚â§ Œ±.\n",
        "\n",
        "- This gives you an objective rule for making decisions.\n",
        "\n",
        "- 3 . Balances Sensitivity and Specificity\n",
        "\n",
        "- A lower Œ± reduces the risk of false positives but increases the chance of Type II errors (failing to detect a true effect).\n",
        "\n",
        "- Choosing Œ± depends on context.\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "- The p-value is a key concept in hypothesis testing. It helps you determine the strength of the evidence against the null hypothesis (H‚ÇÄ).\n",
        "- Definition\n",
        "A p-value is the probability of observing a result as extreme as (or more extreme than) the one obtained, assuming the null hypothesis is true.\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "- The p-value helps you determine whether the results of your test are statistically significant ‚Äî that is, whether they are likely due to chance or not.\n",
        "-  Basic Interpretation\n",
        "- The p-value is the probability of observing your sample results, or something more extreme, if the null hypothesis (H‚ÇÄ) is actually true.\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "- When you perform a hypothesis test, there are two types of errors you can make ‚Äî called Type I and Type II errors. These relate to the correctness of your decision about the null hypothesis (H‚ÇÄ).\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "- The tail of a test refers to where you‚Äôre looking for evidence against the null hypothesis (H‚ÇÄ) ‚Äî in one direction (one-tailed) or both (two-tailed).\n",
        "- 1. One-Tailed Test\n",
        "Definition: Tests for an effect in only one direction.\n",
        "\n",
        "- You use it when you're only interested in greater than or less than.\n",
        "\n",
        "- Example hypotheses:\n",
        "\n",
        "- H‚ÇÄ: Œº = 100\n",
        "\n",
        "- H‚ÇÅ: Œº > 100 (right-tailed)\n",
        "\n",
        "- or: Œº < 100 (left-tailed)\n",
        "- Used When:\n",
        "- You're only concerned if a value increases (or only decreases).\n",
        "\n",
        "- Example: You want to know if a new teaching method improves scores (not just changes them).\n",
        "- 2. Two-Tailed Test\n",
        "- Definition: Tests for an effect in either direction.\n",
        "\n",
        "- You use it when you care about any difference, regardless of direction.\n",
        "\n",
        "- Example hypotheses:\n",
        "\n",
        "- H‚ÇÄ: Œº = 100\n",
        "\n",
        "- H‚ÇÅ: Œº ‚â† 100\n",
        "\n",
        "- Used When:\n",
        "- You're testing for any change, whether it‚Äôs an increase or a decrease.\n",
        "\n",
        "- Example: You want to test if a new drug changes blood pressure ‚Äî up or down.\n",
        "8.  What is the Z-test, and when is it used in hypothesis testing?\n",
        "- The Z-test is a statistical test used to determine whether there is a significant difference between sample and population means (or between two sample means) when the population standard deviation is known and the sample size is large.\n",
        "-  When to Use a Z-Test\n",
        "- You use a Z-test when ALL of the following conditions are met:\n",
        "\n",
        "- a.  Population standard deviation (œÉ) is known\n",
        "\n",
        "- b.   Sample size is large (n ‚â• 30) ‚Äî Central Limit Theorem applies\n",
        "- c.  Data is approximately normally distributed (or n is large enough)\n",
        "\n",
        "- d .  You're comparing:\n",
        "\n",
        "- A sample mean to a population mean\n",
        "\n",
        "- Two sample means from independent large samples\n",
        "9.  How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "- A Z-score is a standardized value that tells you how many standard deviations a data point or sample statistic is from the population mean.\n",
        "\n",
        "- In hypothesis testing, the Z-score is used to determine how unusual your sample result is under the assumption that the null hypothesis (H‚ÇÄ) is true.\n",
        "\n",
        "-  Formula for Z-Score (One-Sample Mean Test)\n",
        "ùëç\n",
        "=\n",
        "ùëã\n",
        "Àâ\n",
        "‚àí\n",
        "ùúá\n",
        "ùúé\n",
        "/\n",
        "ùëõ\n",
        "Z=\n",
        "œÉ/\n",
        "n\n",
        "‚Äã\n",
        "\n",
        "X\n",
        "Àâ\n",
        " ‚àíŒº\n",
        "‚Äã\n",
        "\n",
        "- Where:\n",
        "\n",
        "- ùëã\n",
        "Àâ\n",
        "X\n",
        "Àâ\n",
        "  = sample mean\n",
        "\n",
        "- ùúá\n",
        "Œº = population mean (under H‚ÇÄ)\n",
        "\n",
        "- ùúé\n",
        "œÉ = population standard deviation\n",
        "\n",
        "- ùëõ\n",
        "n = sample size\n",
        "- What the Z-Score Represents\n",
        "- A Z-score of 0 means the sample mean is exactly equal to the population mean.\n",
        "\n",
        "- A positive Z-score means the sample mean is above the population mean.\n",
        "\n",
        "- A negative Z-score means the sample mean is below the population mean.\n",
        "\n",
        "- The larger the absolute value, the further away the sample is from the null hypothesis ‚Äî indicating stronger evidence against H‚ÇÄ.\n",
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "- The T-distribution (also called Student's t-distribution) is a probability distribution that is similar to the normal distribution, but it has heavier tails. It's used in hypothesis testing and confidence intervals when you're working with small samples or unknown population standard deviation.\n",
        "- When to Use the T-Distribution Instead of the Normal (Z) Distribution\n",
        "\n",
        "| Use the **T-distribution** when:                                      |\n",
        "| --------------------------------------------------------------------- |\n",
        "| ‚úÖ The **sample size is small** (n < 30)                               |\n",
        "| ‚úÖ The **population standard deviation (œÉ) is unknown**                |\n",
        "| ‚úÖ You're estimating the **mean** of a normally distributed population |\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test?\n",
        "\n",
        "| Aspect                   | **Z-Test**                                    | **T-Test**                                |\n",
        "| ------------------------ | --------------------------------------------- | ----------------------------------------- |\n",
        "| **Population SD (œÉ)**    | Known                                         | Unknown (use sample SD instead)           |\n",
        "| **Sample Size (n)**      | Large (usually n ‚â• 30)                        | Small or any size if œÉ unknown            |\n",
        "| **Distribution Used**    | Standard normal distribution (Z-distribution) | Student's t-distribution                  |\n",
        "| **Test Statistic**       | $Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}$ | $t = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}}$  |\n",
        "| **Variability Estimate** | Uses **population** standard deviation        | Uses **sample** standard deviation        |\n",
        "| **When to Use**          | When œÉ is known and sample size is large      | When œÉ is unknown or sample size is small |\n",
        "\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "- The T-test is a statistical method used to determine if there is a significant difference between the means of two groups or between a sample mean and a population mean when the population standard deviation is unknown.\n",
        "\n",
        "- It relies on the t-distribution, which accounts for the extra uncertainty from estimating the population standard deviation from the sample.\n",
        "- How It‚Äôs Used in Hypothesis Testing\n",
        "- 1 . Set hypotheses:\n",
        "\n",
        "- Null hypothesis\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        " : The means are equal (no difference).\n",
        "\n",
        "- Alternative hypothesis\n",
        "ùêª\n",
        "1\n",
        "H\n",
        "1\n",
        "‚Äã\n",
        " : The means are different.\n",
        "\n",
        "- Calculate the t-statistic using the formula above.\n",
        "\n",
        "- Find the critical t-value from the t-distribution table based on your chosen significance level (Œ±) and degrees of freedom (df = n‚àí1).\n",
        "\n",
        "- Compare the calculated t-statistic with the critical value:\n",
        "\n",
        "- If\n",
        "‚à£\n",
        "ùë°\n",
        "‚à£\n",
        ">\n",
        "ùë°\n",
        "ùëê\n",
        "ùëü\n",
        "ùëñ\n",
        "ùë°\n",
        "ùëñ\n",
        "ùëê\n",
        "ùëé\n",
        "ùëô\n",
        "‚à£t‚à£>t\n",
        "critical\n",
        "‚Äã\n",
        " , reject\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        "  (evidence for difference).\n",
        "\n",
        "Otherwise, fail to reject\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        " .\n",
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "-\n",
        "\n",
        "| Feature                               | Z-Test                                        | T-Test                                                         |\n",
        "| ------------------------------------- | --------------------------------------------- | -------------------------------------------------------------- |\n",
        "| **Use Case**                          | Large sample sizes (n ‚â• 30)                   | Small sample sizes (n < 30)                                    |\n",
        "| **Population Standard Deviation (œÉ)** | Known                                         | Unknown; sample standard deviation (s) is used                 |\n",
        "| **Distribution**                      | Standard Normal Distribution (Z-distribution) | Student‚Äôs T-Distribution                                       |\n",
        "| **Tail Thickness**                    | Thinner tails                                 | Thicker tails (accounts for more uncertainty in small samples) |\n",
        "| **Converges to Z-test?**              | N/A                                           | Yes, as sample size increases, T approaches Z                  |\n",
        "\n",
        "14.  What is a confidence interval, and how is it used to interpret statistical results?\n",
        "- A confidence interval (CI) is a range of values, derived from sample data, that is likely to contain the true population parameter (such as the mean or proportion) with a certain level of confidence.\n",
        "-  Use in Statistical Results\n",
        "- Estimate Uncertainty: CIs give a range that reflects uncertainty due to sampling variability.\n",
        "\n",
        "- Hypothesis Testing: If the CI does not contain the value stated in the null hypothesis then the null hypothesis can be rejected.\n",
        "\n",
        "- Comparison of Groups: Overlapping CIs between groups may suggest no significant difference; non-overlapping CIs suggest a significant difference.\n",
        "15.  What is the margin of error, and how does it affect the confidence interval?\n",
        "- The margin of error is the amount added to and subtracted from the sample estimate (like a sample mean or proportion) to create a confidence interval (CI).\n",
        "\n",
        "- It reflects the maximum expected difference between the true population value and the sample estimate, given a certain level of confidence.\n",
        "- How It Affects the Confidence Interval\n",
        "- The margin of error directly determines the width of the confidence interval:\n",
        "\n",
        "CI = Sample estimate ¬± Margin of Error\n",
        "\n",
        "So:\n",
        "\n",
        "- Larger MOE ‚Üí Wider CI ‚Üí Less precision\n",
        "\n",
        "- Smaller MOE ‚Üí Narrower CI ‚Üí More precision\n",
        "16.How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "- Bayes' Theorem is a fundamental concept in probability and statistics that describes how to update the probability of a hypothesis when given new evidence.\n",
        "-  Significance of Bayes‚Äô Theorem\n",
        "- Flexible: Works well when data is limited or uncertain.\n",
        "\n",
        "- Incorporates Prior Knowledge: Especially useful in real-world scenarios where background knowledge matters.\n",
        "\n",
        "- Interpretable Probabilities: Gives direct probabilistic statements about hypotheses (unlike frequentist p-values).\n",
        "17. What is the Chi-square distribution, and when is it used?\n",
        "- The Chi-square distribution (œá¬≤) is a right-skewed probability distribution that arises when you sum the squares of independent standard normal variables. It‚Äôs commonly used in hypothesis testing involving categorical data.\n",
        "- When Is the Chi-Square Distribution Used?\n",
        "1. Chi-Square Test of Independence\n",
        "Use: To test whether two categorical variables are independent.\n",
        "\n",
        "Example: Is gender independent of voting preference?\n",
        "\n",
        "2. Chi-Square Goodness-of-Fit Test\n",
        "Use: To test whether an observed distribution fits an expected distribution.\n",
        "\n",
        "Example: Do dice rolls follow a uniform distribution?\n",
        "\n",
        "3. Chi-Square Test for Homogeneity\n",
        "Use: To compare the distribution of a categorical variable across multiple groups.\n",
        "\n",
        "Example: Do different brands have the same defect rate?\n",
        "\n",
        "4. In Confidence Intervals for Variances\n",
        "The chi-square distribution is used to construct confidence intervals for population variance when data is normally distributed.\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "- The Chi-square goodness of fit test is a statistical test used to determine whether a sample's categorical data fits a theoretical or expected distribution.\n",
        "-  How to Apply the Test (Step-by-Step)\n",
        "- Example Scenario\n",
        "- You roll a die 60 times. You expect each face (1‚Äì6) to appear 10 times if the die is fair.\n",
        "\n",
        "- Observed frequencies:\n",
        "\n",
        "- [8, 9, 10, 11, 12, 10]\n",
        "\n",
        "- Expected frequencies (under H‚ÇÄ):\n",
        "\n",
        "- [10, 10, 10, 10, 10, 10]\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "- The F-distribution is a continuous probability distribution used in hypothesis testing, particularly when comparing variances between two or more groups. It's commonly used in the F-test, which is a statistical test to determine if there are significant differences in the means of two or more groups. The F-distribution helps determine the probability of observing a given F-statistic under the assumption that there are no real differences between the groups being compared.\n",
        "- When is it used?\n",
        "-  The F-distribution is primarily used in hypothesis testing to:\n",
        "- 1 . Compare variances: It's used to test if the variances of two samples are equal or if they are significantly different.\n",
        "- 2 . Assess the overall significance of a regression model: In regression analysis, the F-test assesses whether the regression model as a whole is significant, meaning whether the explained variance by the model is significantly greater than the unexplained variance.\n",
        "- 3 . Compare multiple means (ANOVA): The F-test is used in ANOVA (Analysis of Variance) to determine if there are significant differences between the means of two or more groups.\n",
        "20. What is an ANOVA test, and what are its assumptions?\n",
        "- An ANOVA (Analysis of Variance) test is a statistical method used to compare the means of three or more groups to determine if there are any statistically significant differences between them. It helps answer the question: Are the observed differences among group means due to random chance, or do they reflect true differences in the population?\n",
        "- Assumptions of ANOVA\n",
        "- To ensure the validity of an ANOVA, several assumptions must be met:\n",
        "\n",
        "- 1 . Independence of observations:\n",
        "\n",
        "- Each sample or group must be collected independently of the others.\n",
        "\n",
        "- Violated if the same individuals are used in multiple groups (unless using repeated measures ANOVA).\n",
        "\n",
        "- 2 . Normality:\n",
        "\n",
        "- The data within each group should be approximately normally distributed.\n",
        "\n",
        "- This is especially important for small sample sizes; for large samples, the Central Limit Theorem often mitigates this concern.\n",
        "\n",
        "- 3 . Homogeneity of variance (homoscedasticity):\n",
        "\n",
        "- The variances among the groups should be roughly equal.\n",
        "\n",
        "- Can be tested using Levene‚Äôs test or Bartlett‚Äôs test.\n",
        "21.What are the different types of ANOVA tests?\n",
        "- 1. One-Way ANOVA\n",
        "- Purpose: Tests for differences between means of three or more independent groups based on one independent variable (factor).\n",
        "\n",
        "- Example: Comparing test scores across students from three different teaching methods.\n",
        "- 2. Two-Way ANOVA\n",
        "- Purpose: Tests the effect of two independent variables (factors) on a dependent variable, and also tests for interaction between the two factors.\n",
        "\n",
        "- Example: Analyzing how both gender and training program affect performance scores.\n",
        "- 3. Repeated Measures ANOVA\n",
        "- Purpose: Used when the same subjects are measured multiple times under different conditions or over time.\n",
        "\n",
        "- Example: Measuring blood pressure of patients before, during, and after treatment.\n",
        "- 4. Mixed-Design (Split-Plot) ANOVA\n",
        "- Purpose: Combines features of between-subjects (independent groups) and within-subjects (repeated measures) designs.\n",
        "\n",
        "- Example: Studying the effect of two teaching methods (between-subjects) over three time points (within-subjects).\n",
        "- 5. Multivariate Analysis of Variance (MANOVA)\n",
        "- Purpose: An extension of ANOVA used when there are multiple dependent variables that are correlated.\n",
        "\n",
        "- Example: Studying how different diets affect both cholesterol level and blood pressure.\n",
        "- 6. Analysis of Covariance (ANCOVA)\n",
        "- Purpose: Combines ANOVA with regression. It adjusts the dependent variable for the effects of one or more covariates (continuous variables).\n",
        "\n",
        "- Example: Comparing student performance across teaching methods while controlling for prior GPA.\n",
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "-The F-test is based on the F-distribution, which arises when comparing two sample variances. The test statistic is the ratio of two variances:\n",
        "\n",
        "ùêπ\n",
        "=\n",
        "Variance\n",
        "1\n",
        "Variance\n",
        "2\n",
        "F=\n",
        "Variance\n",
        "2\n",
        "‚Äã\n",
        "\n",
        "Variance\n",
        "1\n",
        "‚Äã\n",
        "\n",
        "‚Äã\n",
        "\n",
        "- If the two populations have the same variance, this ratio will be close to 1.\n",
        "\n",
        "- A large or small F-value (depending on the hypothesis) may indicate a significant difference between the variances or model components.\n",
        "- Relation to Hypothesis Testing\n",
        "- The F-test is a tool in hypothesis testing used to decide whether to reject the null hypothesis.\n",
        "\n",
        "- It uses the F-distribution to determine critical values.\n",
        "\n",
        "- If the calculated F-statistic is greater than the critical value (or if the p-value is less than the significance level), the null hypothesis is rejected.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bez2fjFaYYCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "1. Write a Python program to generate a random variable and display its value.\n",
        "'''\n",
        "import random\n",
        "\n",
        "# Generate a random variable (e.g., a float between 0 and 1)\n",
        "random_variable = random.random()\n",
        "\n",
        "# Display the value\n",
        "print(\"Generated random variable:\", random_variable)\n",
        "Explanation:\n",
        "random.random() generates a random float between 0.0 and 1.0.\n",
        "\n",
        "The result is printed to the console.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "xGsONXQ5FEHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2.Generate a discrete uniform distribution using Python and plot the probability mass function (PMF).\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define parameters for discrete uniform distribution\n",
        "low = 1   # inclusive lower bound\n",
        "high = 7  # exclusive upper bound (like a 6-sided die)\n",
        "\n",
        "# Create a discrete uniform distribution\n",
        "dist = randint(low, high)\n",
        "\n",
        "# Generate sample values (optional)\n",
        "samples = dist.rvs(size=1000)\n",
        "\n",
        "# Define the range of x values (possible outcomes)\n",
        "x = np.arange(low, high)\n",
        "\n",
        "# Compute the PMF\n",
        "pmf_values = dist.pmf(x)\n",
        "\n",
        "# Plot the PMF\n",
        "plt.stem(x, pmf_values, basefmt=\" \", use_line_collection=True)\n",
        "plt.title(\"PMF of Discrete Uniform Distribution (1 to 6)\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        " Explanation:\n",
        "randint(low, high) creates a discrete uniform distribution over integers [low, high-1].\n",
        "\n",
        "rvs(size=1000) generates random samples.\n",
        "\n",
        "pmf(x) calculates the probability mass for each possible outcome.\n",
        "\n",
        "plt.stem() creates a vertical line plot typical for PMFs.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "OVDGGVUpG1rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution.\n",
        "'''\n",
        "def bernoulli_pdf(x, p):\n",
        "    \"\"\"\n",
        "    Calculate the PMF of a Bernoulli distribution.\n",
        "\n",
        "    Parameters:\n",
        "    x (int): The outcome (0 or 1)\n",
        "    p (float): Probability of success (must be between 0 and 1)\n",
        "\n",
        "    Returns:\n",
        "    float: Probability of observing outcome x\n",
        "    \"\"\"\n",
        "    if x not in [0, 1]:\n",
        "        return 0.0\n",
        "    if not (0 <= p <= 1):\n",
        "        raise ValueError(\"Probability p must be between 0 and 1.\")\n",
        "\n",
        "    return p if x == 1 else 1 - p\n",
        "# Example usage\n",
        "p = 0.7  # Probability of success\n",
        "print(\"P(X=0):\", bernoulli_pdf(0, p))  # Should return 0.3\n",
        "print(\"P(X=1):\", bernoulli_pdf(1, p))  # Should return 0.7\n",
        "'''"
      ],
      "metadata": {
        "id": "KsslX64nHWor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Parameters\n",
        "n = 10       # number of trials\n",
        "p = 0.5      # probability of success\n",
        "size = 1000  # number of samples\n",
        "\n",
        "# Simulate binomial distribution\n",
        "samples = np.random.binomial(n, p, size)\n",
        "\n",
        "# Plot histogram\n",
        "plt.hist(samples, bins=range(n+2), align='left', rwidth=0.8, density=True, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Plot theoretical PMF for comparison\n",
        "x = np.arange(0, n+1)\n",
        "pmf = binom.pmf(x, n, p)\n",
        "plt.plot(x, pmf, 'o-', color='red', label='Theoretical PMF')\n",
        "\n",
        "# Labels and title\n",
        "plt.title(f'Binomial Distribution Histogram (n={n}, p={p})')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "YytBHc1sHuNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. Create a Poisson distribution and visualize it using Python.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Parameters\n",
        "mu = 3  # Mean number of events (Œª in Poisson distribution)\n",
        "x = np.arange(0, 15)  # Values to evaluate the PMF\n",
        "\n",
        "# Compute PMF\n",
        "pmf = poisson.pmf(x, mu)\n",
        "\n",
        "# Plot PMF\n",
        "plt.stem(x, pmf, basefmt=\" \", use_line_collection=True)\n",
        "plt.title(f'Poisson Distribution (Œª = {mu})')\n",
        "plt.xlabel('Number of Events')\n",
        "plt.ylabel('Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        " Explanation:\n",
        "mu (or Œª) is the average number of events in a fixed interval.\n",
        "\n",
        "poisson.pmf(x, mu) calculates the probability mass function for each value in x.\n",
        "\n",
        "plt.stem() is used for plotting PMFs (discrete probabilities).\n",
        "'''"
      ],
      "metadata": {
        "id": "i1Ycpa5XHuBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_IpYgjzWePB"
      },
      "outputs": [],
      "source": [
        "6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete\n",
        "uniform distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define parameters\n",
        "low = 1   # Inclusive lower bound\n",
        "high = 7  # Exclusive upper bound (e.g., like a 6-sided die: 1 to 6)\n",
        "\n",
        "# Create discrete uniform distribution\n",
        "dist = randint(low, high)\n",
        "\n",
        "# Values for which to calculate the CDF\n",
        "x = np.arange(low - 1, high + 1)  # Include one value before and after range for visualization\n",
        "cdf_values = dist.cdf(x)\n",
        "\n",
        "# Plot CDF\n",
        "plt.step(x, cdf_values, where='post', label='CDF', color='blue')\n",
        "plt.scatter(x, cdf_values, color='red')  # Show points for clarity\n",
        "plt.title('CDF of Discrete Uniform Distribution (1 to 6)')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.xticks(np.arange(low - 1, high + 1))\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.legend()\n",
        "plt.show()\n",
        " Explanation:\n",
        "randint(low, high) creates a discrete uniform distribution over integers\n",
        "[\n",
        "ùëô\n",
        "ùëú\n",
        "ùë§\n",
        ",\n",
        "‚Ñé\n",
        "ùëñ\n",
        "ùëî\n",
        "‚Ñé\n",
        "‚àí\n",
        "1\n",
        "]\n",
        "[low,high‚àí1].\n",
        "\n",
        "cdf(x) computes the cumulative probability up to and including each value in x.\n",
        "\n",
        "plt.step(..., where='post') creates a stepwise plot suitable for CDFs of discrete distributions.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "7.Generate a continuous uniform distribution using NumPy and visualize it.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Parameters for the uniform distribution\n",
        "a = 0   # Lower bound\n",
        "b = 10  # Upper bound\n",
        "size = 1000  # Number of samples\n",
        "\n",
        "# Generate samples from a continuous uniform distribution\n",
        "samples = np.random.uniform(low=a, high=b, size=size)\n",
        "\n",
        "# Plot histogram of the samples\n",
        "plt.hist(samples, bins=30, density=True, alpha=0.6, color='skyblue', edgecolor='black', label='Sample Histogram')\n",
        "\n",
        "# Plot the theoretical PDF\n",
        "x = np.linspace(a, b, 1000)\n",
        "pdf = uniform.pdf(x, loc=a, scale=b-a)\n",
        "plt.plot(x, pdf, 'r-', lw=2, label='Theoretical PDF')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.title(f'Continuous Uniform Distribution U({a}, {b})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "Explanation:\n",
        "np.random.uniform(low, high, size) generates samples from a continuous uniform distribution over\n",
        "[\n",
        "ùëé\n",
        ",\n",
        "ùëè\n",
        ")\n",
        "[a,b).\n",
        "\n",
        "uniform.pdf(x, loc=a, scale=b-a) gives the probability density function for the continuous uniform distribution.\n",
        "\n",
        "plt.hist(..., density=True) normalizes the histogram so it represents a probability density.\n",
        "'''"
      ],
      "metadata": {
        "id": "rMd4aLrVJUQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8. Write a Python function to calculate Z-scores from a dataset and plot them.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_and_plot_z_scores(data):\n",
        "    \"\"\"\n",
        "    Calculate Z-scores from a dataset and plot them.\n",
        "\n",
        "    Parameters:\n",
        "    data (list or np.ndarray): The input dataset.\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if std == 0:\n",
        "        raise ValueError(\"Standard deviation is zero, Z-scores are undefined.\")\n",
        "\n",
        "    # Calculate Z-scores\n",
        "    z_scores = (data - mean) / std\n",
        "\n",
        "    # Plot Z-scores\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(z_scores, marker='o', linestyle='-', color='blue', label='Z-scores')\n",
        "    plt.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
        "    plt.axhline(1, color='red', linestyle='--', linewidth=1, label='¬±1 SD')\n",
        "    plt.axhline(-1, color='red', linestyle='--', linewidth=1)\n",
        "    plt.title('Z-scores of Dataset')\n",
        "    plt.xlabel('Data Point Index')\n",
        "    plt.ylabel('Z-score')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "# Example dataset\n",
        "data = [10, 12, 9, 15, 18, 7, 11, 13, 10, 14]\n",
        "\n",
        "# Calculate and plot Z-scores\n",
        "z = calculate_and_plot_z_scores(data)\n",
        "print(\"Z-scores:\", z)\n",
        "'''"
      ],
      "metadata": {
        "id": "frnjy4BoJ4Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Parameters\n",
        "original_dist = np.random.exponential(scale=2.0, size=100000)  # Non-normal original distribution\n",
        "sample_size = 30           # Size of each sample\n",
        "num_samples = 1000         # Number of samples to draw\n",
        "\n",
        "# Collect sample means\n",
        "sample_means = []\n",
        "\n",
        "for _ in range(num_samples):\n",
        "    sample = np.random.choice(original_dist, size=sample_size, replace=False)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# Plot original distribution\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(original_dist, bins=50, kde=True, color='skyblue')\n",
        "plt.title('Original Distribution (Exponential)')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Plot sampling distribution of the mean\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(sample_means, bins=30, kde=True, color='orange')\n",
        "plt.title(f'Sampling Distribution of the Mean\\n(n={sample_size}, samples={num_samples})')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        " Explanation:\n",
        "Original Distribution: Exponential (which is skewed and non-normal).\n",
        "\n",
        "Sample Size: Each sample contains 30 observations.\n",
        "\n",
        "Number of Samples: 1000 means are calculated from repeated sampling.\n",
        "\n",
        "The left plot shows the original (non-normal) distribution.\n",
        "\n",
        "The right plot shows that the distribution of sample means is approximately normal, as predicted by the CLT.\n",
        "'''"
      ],
      "metadata": {
        "id": "85lN7RvjKOfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10. Simulate data from a normal distribution and plot its histogram.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mean = 0       # Mean (Œº)\n",
        "std_dev = 1    # Standard deviation (œÉ)\n",
        "sample_size = 1000  # Number of data points\n",
        "\n",
        "# Generate random samples from the normal distribution\n",
        "data = np.random.normal(loc=mean, scale=std_dev, size=sample_size)\n",
        "\n",
        "# Plot histogram\n",
        "plt.hist(data, bins=30, density=True, alpha=0.7, color='purple', edgecolor='black')\n",
        "\n",
        "plt.title('Histogram of Normally Distributed Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "PKl7M8q0KoVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11. Simulate multiple samples from a normal distribution and verify the Central Limit Theorem.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for nicer plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Parameters for the original normal distribution\n",
        "mu = 5       # Mean\n",
        "sigma = 2    # Std deviation\n",
        "sample_size = 30   # Number of data points per sample\n",
        "num_samples = 1000  # Number of samples\n",
        "\n",
        "# Step 1 & 2: Generate samples and compute their means\n",
        "sample_means = [\n",
        "    np.mean(np.random.normal(loc=mu, scale=sigma, size=sample_size))\n",
        "    for _ in range(num_samples)\n",
        "]\n",
        "\n",
        "# Plot histogram of sample means\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(sample_means, bins=30, kde=True, color='skyblue')\n",
        "plt.title(f'Distribution of Sample Means (n={sample_size}, samples={num_samples})')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "..."
      ],
      "metadata": {
        "id": "mCDvfuTyLLd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "12. Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1).\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal():\n",
        "    \"\"\"\n",
        "    Calculate and plot the PDF of the standard normal distribution (mean=0, std=1).\n",
        "    \"\"\"\n",
        "    # Define the range of x values\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "\n",
        "    # Calculate the PDF of the standard normal distribution\n",
        "    pdf = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "    # Plot the PDF\n",
        "    plt.plot(x, pdf, label='Standard Normal PDF', color='blue')\n",
        "    plt.title('Standard Normal Distribution (mean=0, std=1)')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function\n",
        "plot_standard_normal()\n",
        "'''"
      ],
      "metadata": {
        "id": "5dpK78UxLeG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13. Generate random variables and calculate their corresponding probabilities using the binomial distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Parameters\n",
        "n = 10        # number of trials\n",
        "p = 0.5       # probability of success per trial\n",
        "size = 20     # number of random variables to generate\n",
        "\n",
        "# Generate random variables (number of successes)\n",
        "random_vars = np.random.binomial(n, p, size)\n",
        "\n",
        "# Calculate corresponding probabilities (PMF)\n",
        "pmf_values = binom.pmf(random_vars, n, p)\n",
        "\n",
        "# Display results\n",
        "for rv, pmf in zip(random_vars, pmf_values):\n",
        "    print(f\"Random variable (successes) = {rv}, PMF = {pmf:.4f}\")\n",
        "Explanation:\n",
        "np.random.binomial(n, p, size) generates size samples from a binomial distribution.\n",
        "\n",
        "binom.pmf(x, n, p) calculates the probability of observing exactly x successes in n trials.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "KWpMjVJeLviU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal\n",
        "distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_z_score(data, x):\n",
        "    \"\"\"\n",
        "    Calculate the Z-score for a given data point x in dataset data.\n",
        "    \"\"\"\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "    if std == 0:\n",
        "        raise ValueError(\"Standard deviation is zero; Z-score is undefined.\")\n",
        "    z = (x - mean) / std\n",
        "    return z\n",
        "\n",
        "def plot_z_score_on_standard_normal(z):\n",
        "    \"\"\"\n",
        "    Plot the standard normal distribution and mark the given Z-score.\n",
        "    \"\"\"\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x, 0, 1)\n",
        "\n",
        "    plt.plot(x, y, label='Standard Normal Distribution')\n",
        "    plt.fill_between(x, 0, y, where=(x <= z), color='skyblue', alpha=0.5, label=f'Area ‚â§ Z={z:.2f}')\n",
        "    plt.axvline(z, color='red', linestyle='--', label=f'Z-score = {z:.2f}')\n",
        "    plt.title('Standard Normal Distribution with Z-score')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Example dataset\n",
        "data = [10, 12, 9, 15, 18, 7, 11, 13, 10, 14]\n",
        "\n",
        "# Data point to calculate Z-score for\n",
        "x_point = 15\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = calculate_z_score(data, x_point)\n",
        "print(f\"Z-score for data point {x_point}: {z_score:.2f}\")\n",
        "\n",
        "# Plot Z-score on standard normal distribution\n",
        "plot_z_score_on_standard_normal(z_score)\n",
        "..."
      ],
      "metadata": {
        "id": "azSU4GRwL_fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "15. Implement hypothesis testing using Z-statistics for a sample dataset.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test(sample, mu_0, alpha=0.05, alternative='two-sided'):\n",
        "    \"\"\"\n",
        "    Perform a Z-test for the mean of a sample.\n",
        "\n",
        "    Parameters:\n",
        "    - sample: array-like, sample data\n",
        "    - mu_0: float, hypothesized population mean under H0\n",
        "    - alpha: significance level (default 0.05)\n",
        "    - alternative: 'two-sided', 'less', or 'greater'\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: computed Z statistic\n",
        "    - p_value: p-value of the test\n",
        "    - conclusion: whether to reject H0\n",
        "    \"\"\"\n",
        "    sample = np.array(sample)\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_std = np.std(sample, ddof=1)  # sample standard deviation\n",
        "\n",
        "    # For Z-test, assume population std known or use sample std for demonstration\n",
        "    # Here we treat sample std as population std (only for demonstration)\n",
        "    std_error = sample_std / np.sqrt(n)\n",
        "\n",
        "    z_stat = (sample_mean - mu_0) / std_error\n",
        "\n",
        "    # Calculate p-value based on alternative hypothesis\n",
        "    if alternative == 'two-sided':\n",
        "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "    elif alternative == 'less':\n",
        "        p_value = norm.cdf(z_stat)\n",
        "    elif alternative == 'greater':\n",
        "        p_value = 1 - norm.cdf(z_stat)\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be 'two-sided', 'less', or 'greater'\")\n",
        "\n",
        "    # Conclusion\n",
        "    reject = p_value < alpha\n",
        "    conclusion = \"Reject the null hypothesis\" if reject else \"Fail to reject the null hypothesis\"\n",
        "\n",
        "    return z_stat, p_value, conclusion\n",
        "\n",
        "# Example usage:\n",
        "sample_data = [12, 15, 14, 10, 13, 15, 16, 14, 13, 12]\n",
        "hypothesized_mean = 13\n",
        "alpha_level = 0.05\n",
        "\n",
        "z_stat, p_val, result = z_test(sample_data, hypothesized_mean, alpha=alpha_level, alternative='two-sided')\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.3f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "print(f\"Test result: {result}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "x2N0eyexMcSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "16. Create a confidence interval for a dataset using Python and interpret the result.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the mean of the data.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or numpy array of sample data\n",
        "    - confidence: confidence level (default 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): tuple representing the confidence interval\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)  # Standard error of the mean\n",
        "\n",
        "    # t critical value for two-tailed test\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example dataset\n",
        "sample_data = [12, 15, 14, 10, 13, 15, 16, 14, 13, 12]\n",
        "\n",
        "# Calculate 95% confidence interval\n",
        "ci_lower, ci_upper = confidence_interval(sample_data, confidence=0.95)\n",
        "mean_val = np.mean(sample_data)\n",
        "\n",
        "print(f\"Sample mean = {mean_val:.2f}\")\n",
        "print(f\"95% Confidence interval = ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the mean of the data.\n",
        "\n",
        "    Parameters:\n",
        "    - data: list or numpy array of sample data\n",
        "    - confidence: confidence level (default 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): tuple representing the confidence interval\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)  # Standard error of the mean\n",
        "\n",
        "    # t critical value for two-tailed test\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    margin_of_error = t_crit * std_err\n",
        "\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "Interpretation:\n",
        "The 95% confidence interval means: We are 95% confident that the true population mean lies between\n",
        "lower¬†bound\n",
        "lower¬†bound and\n",
        "upper¬†bound\n",
        "upper¬†bound.\n",
        "\n",
        "For example, if the output is:Sample mean = 13.40\n",
        "95% Confidence interval = (12.09, 14.71)\n",
        "'''"
      ],
      "metadata": {
        "id": "VHq8d2szM1p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "17.Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Generate data from a normal distribution\n",
        "np.random.seed(42)  # For reproducibility\n",
        "mu, sigma = 50, 5  # Mean and standard deviation\n",
        "sample_size = 100\n",
        "\n",
        "data = np.random.normal(loc=mu, scale=sigma, size=sample_size)\n",
        "\n",
        "# Step 2: Calculate confidence interval for the mean\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    std_err = stats.sem(data)  # Standard error of the mean\n",
        "    t_crit = stats.t.ppf((1 + confidence) / 2, df=n-1)  # t-critical value\n",
        "    margin_of_error = t_crit * std_err\n",
        "    return mean - margin_of_error, mean + margin_of_error\n",
        "\n",
        "ci_lower, ci_upper = confidence_interval(data, confidence=0.95)\n",
        "sample_mean = np.mean(data)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(f\"Sample mean: {sample_mean:.2f}\")\n",
        "print(f\"95% Confidence interval for the mean: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "\n",
        "# Interpretation\n",
        "print(f\"\\nInterpretation: We are 95% confident that the true population mean lies between {ci_lower:.2f} and {ci_upper:.2f}.\")\n",
        "What this does:\n",
        "Generates 100 samples from a normal distribution with mean 50 and std dev 5.\n",
        "\n",
        "Calculates the 95% confidence interval using the t-distribution.\n",
        "\n",
        "Prints the sample mean and the confidence interval.\n",
        "\n",
        "Provides an interpretation of the confidence interval.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "iZaLSXkBNidb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "18.Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mean = 0      # Mean (Œº)\n",
        "std_dev = 1   # Standard deviation (œÉ)\n",
        "\n",
        "# Generate x values over which to compute the PDF\n",
        "x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 1000)\n",
        "\n",
        "# Calculate the PDF values\n",
        "pdf_values = norm.pdf(x, loc=mean, scale=std_dev)\n",
        "\n",
        "# Plot the PDF\n",
        "plt.plot(x, pdf_values, color='navy', lw=2)\n",
        "plt.title('Probability Density Function of Normal Distribution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "What this does:\n",
        "Defines a normal distribution with mean 0 and standard deviation 1.\n",
        "\n",
        "Computes the PDF over a range covering ¬±4 standard deviations.\n",
        "\n",
        "Plots the PDF curve.\n",
        "'''"
      ],
      "metadata": {
        "id": "EwHOUDe0N696"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "19.Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Parameters for the Poisson distribution\n",
        "lambda_rate = 4  # average rate (mean) of events\n",
        "\n",
        "# Values to evaluate\n",
        "x_values = np.arange(0, 15)\n",
        "\n",
        "# Calculate CDF values for these points\n",
        "cdf_values = poisson.cdf(x_values, mu=lambda_rate)\n",
        "\n",
        "# Plot the CDF\n",
        "plt.step(x_values, cdf_values, where='post', color='green')\n",
        "plt.title('CDF of Poisson Distribution (Œª=4)')\n",
        "plt.xlabel('Number of events')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Interpret the CDF at a specific value\n",
        "k = 5\n",
        "cdf_at_k = poisson.cdf(k, mu=lambda_rate)\n",
        "print(f\"P(X ‚â§ {k}) = {cdf_at_k:.4f}\")\n",
        "\n",
        "# Interpretation:\n",
        "print(f\"This means there is a {cdf_at_k*100:.2f}% chance of observing {k} or fewer events.\")\n",
        "Explanation:\n",
        "poisson.cdf(k, mu) calculates the probability that the Poisson random variable\n",
        "ùëã\n",
        "X is less than or equal to\n",
        "ùëò\n",
        "k.\n",
        "\n",
        "The plot shows how the cumulative probability grows with\n",
        "ùëò\n",
        "k.\n",
        "\n",
        "The printed statement explains the probability of observing up to\n",
        "ùëò\n",
        "k events.\n",
        "'''"
      ],
      "metadata": {
        "id": "MxEDgdE6ONNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "20. Simulate a random variable using a continuous uniform distribution and calculate its expected value.\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the continuous uniform distribution\n",
        "a = 2   # lower bound\n",
        "b = 10  # upper bound\n",
        "sample_size = 10000\n",
        "\n",
        "# Step 1: Simulate random variables\n",
        "data = np.random.uniform(low=a, high=b, size=sample_size)\n",
        "\n",
        "# Step 2: Calculate the expected value (mean)\n",
        "\n",
        "# Theoretical expected value of Uniform(a, b) = (a + b) / 2\n",
        "expected_value_theoretical = (a + b) / 2\n",
        "\n",
        "# Empirical expected value (sample mean)\n",
        "expected_value_empirical = np.mean(data)\n",
        "\n",
        "print(f\"Theoretical expected value: {expected_value_theoretical:.2f}\")\n",
        "print(f\"Empirical expected value from simulation: {expected_value_empirical:.2f}\")\n",
        "Explanation:\n",
        "The theoretical expected value of a continuous uniform distribution\n",
        "ùëà\n",
        "(\n",
        "ùëé\n",
        ",\n",
        "ùëè\n",
        ")\n",
        "U(a,b) is\n",
        "ùëé\n",
        "+\n",
        "ùëè\n",
        "2\n",
        "2\n",
        "a+b\n",
        "‚Äã\n",
        " .\n",
        "\n",
        "The empirical expected value is calculated as the mean of the simulated random variables.\n",
        "\n",
        "With a large enough sample size, the empirical mean should be close to the theoretical mean.\n",
        "'''"
      ],
      "metadata": {
        "id": "DEN94smrOgBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "21. Write a Python program to compare the standard deviations of two datasets and visualize the difference.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample datasets\n",
        "data1 = np.random.normal(loc=10, scale=2, size=100)\n",
        "data2 = np.random.normal(loc=10, scale=5, size=100)\n",
        "\n",
        "# Calculate standard deviations\n",
        "std1 = np.std(data1, ddof=1)  # Sample standard deviation\n",
        "std2 = np.std(data2, ddof=1)\n",
        "\n",
        "print(f\"Standard deviation of dataset 1: {std1:.2f}\")\n",
        "print(f\"Standard deviation of dataset 2: {std2:.2f}\")\n",
        "\n",
        "# Plotting histograms with std deviation shaded region\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Dataset 1 histogram\n",
        "plt.hist(data1, bins=20, alpha=0.6, color='blue', label='Dataset 1')\n",
        "plt.axvline(np.mean(data1), color='blue', linestyle='--', label='Mean Dataset 1')\n",
        "plt.axvspan(np.mean(data1) - std1, np.mean(data1) + std1, alpha=0.2, color='blue', label='¬±1 Std Dev (Dataset 1)')\n",
        "\n",
        "# Dataset 2 histogram\n",
        "plt.hist(data2, bins=20, alpha=0.6, color='orange', label='Dataset 2')\n",
        "plt.axvline(np.mean(data2), color='orange', linestyle='--', label='Mean Dataset 2')\n",
        "plt.axvspan(np.mean(data2) - std2, np.mean(data2) + std2, alpha=0.2, color='orange', label='¬±1 Std Dev (Dataset 2)')\n",
        "\n",
        "plt.title('Comparison of Standard Deviations Between Two Datasets')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "PdVYA4sKO0Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "22. Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import iqr\n",
        "\n",
        "# Generate data from a normal distribution\n",
        "np.random.seed(42)\n",
        "data = np.random.normal(loc=50, scale=10, size=1000)\n",
        "\n",
        "# Calculate range\n",
        "data_range = np.max(data) - np.min(data)\n",
        "\n",
        "# Calculate interquartile range (IQR)\n",
        "data_iqr = iqr(data)\n",
        "\n",
        "print(f\"Range of the dataset: {data_range:.2f}\")\n",
        "print(f\"Interquartile Range (IQR) of the dataset: {data_iqr:.2f}\")\n",
        "Explanation:\n",
        "Range = max value ‚àí min value.\n",
        "\n",
        "IQR = 75th percentile ‚àí 25th percentile, measures the spread of the middle 50% of data.\n",
        "'''"
      ],
      "metadata": {
        "id": "RHzgX8IyPEd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "23. Implement Z-score normalization on a dataset and visualize its transformation.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate sample data (e.g., skewed data to see effect of normalization)\n",
        "np.random.seed(42)\n",
        "data = np.random.exponential(scale=2, size=1000).reshape(-1, 1)  # exponential data, positive skew\n",
        "\n",
        "# Apply Z-score normalization\n",
        "scaler = StandardScaler()\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# Plot original vs normalized data histograms\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Original Data')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data_normalized, bins=30, color='orange', edgecolor='black')\n",
        "plt.title('Z-score Normalized Data')\n",
        "plt.xlabel('Value (Z-score)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "Explanation:\n",
        "The original data is skewed (exponential).\n",
        "\n",
        "After Z-score normalization, the data is centered around 0 with a standard deviation of 1.\n",
        "\n",
        "The histograms show how the data distribution shifts and scales after normalization.\n",
        "'''"
      ],
      "metadata": {
        "id": "1TljRd_3PTcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal\n",
        "distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "def calculate_skewness_kurtosis(mean=0, std=1, size=1000):\n",
        "    \"\"\"\n",
        "    Generate normal data and calculate skewness and kurtosis.\n",
        "\n",
        "    Parameters:\n",
        "    - mean: mean of the normal distribution\n",
        "    - std: standard deviation of the normal distribution\n",
        "    - size: number of samples\n",
        "\n",
        "    Returns:\n",
        "    - skewness: measure of asymmetry\n",
        "    - kurt: measure of tail heaviness (excess kurtosis)\n",
        "    \"\"\"\n",
        "    data = np.random.normal(loc=mean, scale=std, size=size)\n",
        "    skewness = skew(data)\n",
        "    kurt = kurtosis(data)  # by default, Fisher's definition (excess kurtosis)\n",
        "\n",
        "    return skewness, kurt\n",
        "\n",
        "# Example usage\n",
        "skew_val, kurt_val = calculate_skewness_kurtosis(mean=0, std=1, size=1000)\n",
        "print(f\"Skewness: {skew_val:.4f}\")\n",
        "print(f\"Kurtosis (excess): {kurt_val:.4f}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "9W9NaCytPo29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a one-sample Z-test for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_data: list or array of sample observations\n",
        "    - population_mean: the known population mean (Œº)\n",
        "    - population_std: the known population standard deviation (œÉ)\n",
        "    - alpha: significance level (default = 0.05 for 95% confidence)\n",
        "\n",
        "    Returns:\n",
        "    - z_score, p_value, result (reject or fail to reject H0)\n",
        "    \"\"\"\n",
        "    sample_data = np.array(sample_data)\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Two-tailed test: calculate p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpretation\n",
        "    if p_value < alpha:\n",
        "        result = \"Reject the null hypothesis (significant difference).\"\n",
        "    else:\n",
        "        result = \"Fail to reject the null hypothesis (no significant difference).\"\n",
        "\n",
        "    return z_score, p_value, result\n",
        "\n",
        "# Example\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=52, scale=10, size=30)  # Sample data\n",
        "pop_mean = 50   # Known population mean\n",
        "pop_std = 10    # Known population standard deviation\n",
        "\n",
        "z, p, interpretation = z_test(sample, pop_mean, pop_std)\n",
        "\n",
        "print(f\"Z-score: {z:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(f\"Conclusion: {interpretation}\")\n",
        "Example Output:Z-score: 1.1074\n",
        "P-value: 0.2681\n",
        "Conclusion: Fail to reject the null hypothesis (no significant difference).\n",
        "'''"
      ],
      "metadata": {
        "id": "cW6vslUcVejC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Simulate random sample data (e.g., from a normal distribution)\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=51, scale=10, size=30)  # Simulated sample data\n",
        "\n",
        "# Step 2: Define the known population mean for comparison\n",
        "population_mean = 50  # Hypothesized mean (H0: mu = 50)\n",
        "\n",
        "# Step 3: Perform one-sample t-test\n",
        "t_stat, p_value = stats.ttest_1samp(sample_data, popmean=population_mean)\n",
        "\n",
        "# Step 4: Output results\n",
        "print(f\"Sample mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis (no significant difference).\")\n",
        "Hypothesis:\n",
        "Null Hypothesis (H‚ÇÄ): The sample comes from a population with mean = 50.\n",
        "\n",
        "Alternative Hypothesis (H‚ÇÅ): The sample mean is significantly different from 50.\n",
        "'''"
      ],
      "metadata": {
        "id": "Bj2cGp8zWPsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3.  Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample_data, population_mean, population_std, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test comparing the sample mean to a known population mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_data: array-like, the sample observations\n",
        "    - population_mean: known population mean (H‚ÇÄ)\n",
        "    - population_std: known population standard deviation\n",
        "    - alpha: significance level (default = 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - z_score: computed Z statistic\n",
        "    - p_value: two-tailed p-value\n",
        "    - conclusion: result of hypothesis test\n",
        "    \"\"\"\n",
        "    sample_data = np.array(sample_data)\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    sample_size = len(sample_data)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "    # Two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Conclusion\n",
        "    if p_value < alpha:\n",
        "        conclusion = \"Reject the null hypothesis (significant difference).\"\n",
        "    else:\n",
        "        conclusion = \"Fail to reject the null hypothesis (no significant difference).\"\n",
        "\n",
        "    return z_score, p_value, conclusion\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(0)\n",
        "sample = np.random.normal(loc=52, scale=10, size=40)  # Simulated sample\n",
        "population_mean = 50\n",
        "population_std = 10  # Known population standard deviation\n",
        "\n",
        "z, p, conclusion = one_sample_z_test(sample, population_mean, population_std)\n",
        "print(f\"Z-score: {z:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(f\"Conclusion: {conclusion}\")\n",
        " Interpretation:\n",
        "H‚ÇÄ (null hypothesis): The sample comes from a population with mean = 50.\n",
        "\n",
        "H‚ÇÅ (alternative): The sample mean ‚â† 50 (two-tailed test).\n",
        "\n",
        "Z-score: Measures how far the sample mean is from the population mean in standard error units.\n",
        "\n",
        "P-value: Probability of observing a result as extreme as the sample mean under H‚ÇÄ.\n",
        "'''"
      ],
      "metadata": {
        "id": "C7BMLupxWjGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(42)\n",
        "sample = np.random.normal(loc=52, scale=10, size=40)  # Sample with mean ‚â† population mean\n",
        "\n",
        "# Step 2: Known parameters\n",
        "population_mean = 50\n",
        "population_std = 10\n",
        "alpha = 0.05  # significance level for a two-tailed test\n",
        "\n",
        "# Step 3: Calculate test statistic (Z-score)\n",
        "sample_mean = np.mean(sample)\n",
        "sample_size = len(sample)\n",
        "z_score = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Step 4: Calculate critical Z-values\n",
        "z_critical = norm.ppf(1 - alpha/2)  # two-tailed: ¬±z_critical\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 5: Print results\n",
        "print(f\"Sample mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 6: Visualization\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, label='Standard Normal Distribution')\n",
        "\n",
        "# Shade critical regions\n",
        "plt.fill_between(x, y, where=(x < -z_critical) | (x > z_critical), color='red', alpha=0.3, label='Rejection Region (Œ±=0.05)')\n",
        "# Plot Z-score\n",
        "plt.axvline(z_score, color='blue', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "\n",
        "# Annotate decision\n",
        "decision = \"Reject H‚ÇÄ\" if p_value < alpha else \"Fail to Reject H‚ÇÄ\"\n",
        "plt.title(f\"Two-Tailed Z-Test Visualization: {decision}\")\n",
        "plt.xlabel('Z')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        " Interpretation:\n",
        "Z-score tells how many standard errors the sample mean is from the population mean.\n",
        "\n",
        "Red shaded areas are rejection regions at the 0.05 significance level (2.5% in each tail).\n",
        "\n",
        "If the Z-score falls into these regions, we reject the null hypothesis.\n",
        "'''"
      ],
      "metadata": {
        "id": "sfqlTMKdW24J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def visualize_type1_type2_errors(mu0=0, mu1=1, sigma=1, alpha=0.05, one_tailed=False):\n",
        "    \"\"\"\n",
        "    Visualizes Type I and Type II errors for hypothesis testing.\n",
        "\n",
        "    Parameters:\n",
        "    - mu0: mean under null hypothesis\n",
        "    - mu1: mean under alternative hypothesis\n",
        "    - sigma: standard deviation (assumed same for both distributions)\n",
        "    - alpha: significance level\n",
        "    - one_tailed: set True for one-tailed test, False for two-tailed\n",
        "    \"\"\"\n",
        "    x = np.linspace(mu0 - 4*sigma, mu1 + 4*sigma, 1000)\n",
        "    h0_pdf = norm.pdf(x, mu0, sigma)\n",
        "    h1_pdf = norm.pdf(x, mu1, sigma)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x, h0_pdf, label='H‚ÇÄ Distribution (mean = {:.1f})'.format(mu0), color='blue')\n",
        "    plt.plot(x, h1_pdf, label='H‚ÇÅ Distribution (mean = {:.1f})'.format(mu1), color='green')\n",
        "\n",
        "    # Determine critical value(s)\n",
        "    if one_tailed:\n",
        "        z_crit = norm.ppf(1 - alpha)\n",
        "        crit_value = mu0 + z_crit * sigma\n",
        "        # Shade Type I error (right tail of H‚ÇÄ)\n",
        "        plt.fill_between(x, h0_pdf, where=(x >= crit_value), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "        # Shade Type II error (left side of critical value under H‚ÇÅ)\n",
        "        plt.fill_between(x, h1_pdf, where=(x < crit_value), color='orange', alpha=0.3, label='Type II Error (Œ≤)')\n",
        "        plt.axvline(crit_value, color='black', linestyle='--', label=f'Critical Value = {crit_value:.2f}')\n",
        "    else:\n",
        "        z_crit = norm.ppf(1 - alpha / 2)\n",
        "        crit_low = mu0 - z_crit * sigma\n",
        "        crit_high = mu0 + z_crit * sigma\n",
        "        # Type I error (both tails of H‚ÇÄ)\n",
        "        plt.fill_between(x, h0_pdf, where=(x <= crit_low) | (x >= crit_high), color='red', alpha=0.3, label='Type I Error (Œ±)')\n",
        "        # Type II error (middle area of H‚ÇÅ)\n",
        "        plt.fill_between(x, h1_pdf, where=(x > crit_low) & (x < crit_high), color='orange', alpha=0.3, label='Type II Error (Œ≤)')\n",
        "        plt.axvline(crit_low, color='black', linestyle='--', label=f'Lower Critical = {crit_low:.2f}')\n",
        "        plt.axvline(crit_high, color='black', linestyle='--', label=f'Upper Critical = {crit_high:.2f}')\n",
        "\n",
        "    plt.title(\"Type I and Type II Errors in Hypothesis Testing\")\n",
        "    plt.xlabel(\"Value\")\n",
        "    plt.ylabel(\"Probability Density\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "visualize_type1_type2_errors(mu0=0, mu1=1, sigma=1, alpha=0.05, one_tailed=False)\n",
        "Interpretation:\n",
        "Type I Error (Œ±): Rejecting\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        "  when it is true (red area under\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        " ).\n",
        "\n",
        "Type II Error (Œ≤): Failing to reject\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        "  when\n",
        "ùêª\n",
        "1\n",
        "H\n",
        "1\n",
        "‚Äã\n",
        "  is true (orange area under\n",
        "ùêª\n",
        "1\n",
        "H\n",
        "1\n",
        "‚Äã\n",
        " ).\n",
        " '''"
      ],
      "metadata": {
        "id": "p99JCmeZXJ25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6. Write a Python program to perform an independent T-test and interpret the results.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Step 1: Simulate two independent samples\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=100, scale=15, size=30)  # Group 1\n",
        "group2 = np.random.normal(loc=105, scale=15, size=30)  # Group 2\n",
        "\n",
        "# Step 2: Perform independent two-sample T-test (assumes equal variances by default)\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"Group 1 Mean:\", np.mean(group1))\n",
        "print(\"Group 2 Mean:\", np.mean(group2))\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis (means are significantly different).\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis (no significant difference in means).\")\n",
        " Hypothesis:\n",
        "H‚ÇÄ (Null Hypothesis): The means of the two groups are equal.\n",
        "\n",
        "H‚ÇÅ (Alternative Hypothesis): The means of the two groups are different.\n",
        "'''"
      ],
      "metadata": {
        "id": "_HR1hITTXjsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7.  Perform a paired sample T-test using Python and visualize the comparison results.\n",
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Step 1: Simulate paired data (e.g., before and after a treatment)\n",
        "np.random.seed(42)\n",
        "before = np.random.normal(loc=100, scale=10, size=30)\n",
        "after = before + np.random.normal(loc=-2, scale=5, size=30)  # After treatment\n",
        "\n",
        "# Step 2: Perform paired sample T-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"Before Mean:\", np.mean(before))\n",
        "print(\"After Mean:\", np.mean(after))\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis (significant difference between paired groups).\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis (no significant difference).\")\n",
        "\n",
        "# Step 5: Visualization\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot paired values\n",
        "for i in range(len(before)):\n",
        "    plt.plot([1, 2], [before[i], after[i]], marker='o', color='gray', alpha=0.6)\n",
        "\n",
        "# Means\n",
        "plt.plot([1]*len(before), before, 'bo', label='Before')\n",
        "plt.plot([2]*len(after), after, 'go', label='After')\n",
        "\n",
        "# Formatting\n",
        "plt.xticks([1, 2], ['Before', 'After'])\n",
        "plt.title('Paired Sample Comparison')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "AtpBGxeRX-Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8.  Simulate data and perform both Z-test and T-test, then compare the results using Python.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "np.random.seed(0)\n",
        "sample = np.random.normal(loc=52, scale=10, size=25)  # Mean = 52, SD = 10\n",
        "population_mean = 50\n",
        "population_std = 10  # Known for Z-test\n",
        "\n",
        "# Step 2: Z-test (assumes known population standard deviation)\n",
        "z_score = (np.mean(sample) - population_mean) / (population_std / np.sqrt(len(sample)))\n",
        "p_value_z = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
        "\n",
        "# Step 3: T-test (uses sample standard deviation)\n",
        "t_stat, p_value_t = stats.ttest_1samp(sample, popmean=population_mean)\n",
        "\n",
        "# Step 4: Output results\n",
        "print(\"Sample mean:\", np.mean(sample))\n",
        "print(\"\\n--- Z-Test ---\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value (Z-test): {p_value_z:.4f}\")\n",
        "\n",
        "print(\"\\n--- T-Test ---\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value (T-test): {p_value_t:.4f}\")\n",
        "\n",
        "# Step 5: Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\n--- Conclusion ---\")\n",
        "if p_value_z < alpha:\n",
        "    print(\"Z-Test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Z-Test: Fail to reject the null hypothesis.\")\n",
        "\n",
        "if p_value_t < alpha:\n",
        "    print(\"T-Test: Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"T-Test: Fail to reject the null hypothesis.\")\n",
        "'''"
      ],
      "metadata": {
        "id": "kSKr2eG9YnXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9.  Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or np.array): Sample data\n",
        "        confidence (float): Confidence level (e.g., 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "        Tuple (lower_bound, upper_bound)\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    mean = np.mean(data)\n",
        "    sem = stats.sem(data)  # Standard Error of the Mean\n",
        "    margin = stats.t.ppf((1 + confidence) / 2.0, df=n-1) * sem\n",
        "    return mean - margin, mean + margin\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(1)\n",
        "sample_data = np.random.normal(loc=100, scale=15, size=30)\n",
        "ci = confidence_interval(sample_data, confidence=0.95)\n",
        "print(f\"95% Confidence Interval: ({ci[0]:.2f}, {ci[1]:.2f})\")\n",
        "'''"
      ],
      "metadata": {
        "id": "4d1uQpXJZBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def calculate_margin_of_error(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for a sample mean at a given confidence level.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or np.array): Sample data\n",
        "        confidence (float): Confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "        float: Margin of error\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    n = len(data)\n",
        "    sem = stats.sem(data)  # Standard Error of the Mean\n",
        "    t_score = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "    margin_error = t_score * sem\n",
        "    return margin_error\n",
        "\n",
        "# Example usage\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=50, scale=8, size=40)\n",
        "moe = calculate_margin_of_error(sample_data, confidence=0.95)\n",
        "print(f\"Margin of Error (95% confidence): ¬±{moe:.2f}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "49Fkl3q2ZVA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process.\n",
        "'''\n",
        "def bayes_theorem(prior, likelihood, false_positive_rate):\n",
        "    \"\"\"\n",
        "    Calculate the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "        prior (float): P(H) - Prior probability of hypothesis\n",
        "        likelihood (float): P(E|H) - Likelihood of evidence given hypothesis\n",
        "        false_positive_rate (float): P(E|¬¨H) - Probability of evidence given hypothesis is false\n",
        "\n",
        "    Returns:\n",
        "        float: Posterior probability P(H|E)\n",
        "    \"\"\"\n",
        "    # Total probability of evidence: P(E) = P(E|H)*P(H) + P(E|¬¨H)*P(¬¨H)\n",
        "    prob_evidence = likelihood * prior + false_positive_rate * (1 - prior)\n",
        "\n",
        "    # Posterior probability P(H|E)\n",
        "    posterior = (likelihood * prior) / prob_evidence\n",
        "\n",
        "    return posterior\n",
        "\n",
        "# Given values\n",
        "prior = 0.01                 # P(H)\n",
        "likelihood = 0.99            # P(E|H)\n",
        "false_positive_rate = 0.05   # P(E|¬¨H)\n",
        "\n",
        "posterior = bayes_theorem(prior, likelihood, false_positive_rate)\n",
        "print(f\"Posterior probability (patient has disease given positive test): {posterior:.4f}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "DRuFERheZrKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "12.  Perform a Chi-square test for independence between two categorical variables in Python.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample data: contingency table\n",
        "# Rows = Variable A categories, Columns = Variable B categories\n",
        "# Example: Survey counts of people liking (Yes/No) across two groups (Group 1 and Group 2)\n",
        "data = np.array([[30, 10],\n",
        "                 [20, 40]])\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(\"Expected frequencies:\")\n",
        "print(expected)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis: variables are dependent (association exists).\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: variables are independent (no association).\")\n",
        "Explanation:\n",
        "data is a 2D contingency table with observed counts.\n",
        "\n",
        "The function returns:\n",
        "\n",
        "Chi-square statistic\n",
        "\n",
        "p-value\n",
        "\n",
        "degrees of freedom\n",
        "\n",
        "expected frequencies if the variables were independent.\n",
        "\n",
        "If p-value < alpha (usually 0.05), conclude variables are dependent/associated.\n",
        "'''"
      ],
      "metadata": {
        "id": "y0Gzg7FNZ-Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13.  Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data.\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculate expected frequencies for a Chi-square test.\n",
        "\n",
        "    Parameters:\n",
        "        observed (2D array-like): Observed frequency table (contingency table).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Expected frequency table.\n",
        "    \"\"\"\n",
        "    observed = np.array(observed)\n",
        "    row_sums = observed.sum(axis=1).reshape(-1, 1)  # Sum of each row, column vector\n",
        "    col_sums = observed.sum(axis=0).reshape(1, -1)  # Sum of each column, row vector\n",
        "    total = observed.sum()\n",
        "\n",
        "    expected = (row_sums @ col_sums) / total\n",
        "    return expected\n",
        "\n",
        "# Example observed data (contingency table)\n",
        "observed_data = [\n",
        "    [30, 10, 20],\n",
        "    [20, 40, 15]\n",
        "]\n",
        "\n",
        "expected_freq = calculate_expected_frequencies(observed_data)\n",
        "print(\"Observed Frequencies:\\n\", np.array(observed_data))\n",
        "print(\"\\nExpected Frequencies:\\n\", expected_freq)\n",
        "'''"
      ],
      "metadata": {
        "id": "ICTsqv8waUmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "14.  Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution.\n",
        "'''\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed frequencies (example data)\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "# Expected frequencies - should sum to same total as observed\n",
        "# Here, assume expected proportions are 0.4, 0.4, 0.2\n",
        "total = observed.sum()\n",
        "expected_proportions = np.array([0.4, 0.4, 0.2])\n",
        "expected = expected_proportions * total\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: observed data does NOT fit the expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: observed data fits the expected distribution.\")\n",
        "Explanation:\n",
        "Null hypothesis\n",
        "ùêª\n",
        "0\n",
        "H\n",
        "0\n",
        "‚Äã\n",
        " : The observed data follows the expected distribution.\n",
        "\n",
        "Alternative\n",
        "ùêª\n",
        "1\n",
        "H\n",
        "1\n",
        "‚Äã\n",
        " : The observed data does not follow the expected distribution.\n",
        "\n",
        "The test compares observed counts to expected counts based on the hypothesized distribution.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "J9wLwL2RakFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}